{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione\n",
    "\n",
    "1. Creare tot sistemi diversi (per esempio, lucene, bert, scibert, tabert (con e senza contesto))\n",
    "2. Creare un sottoinsieme dei paper (tipo 20) da usare come ground truth (o a caso oppure con lucene i più rilevanti per argomento che abbiano tabelle interessanti) - cerchiamo di limitare il numero di tabelle a ca. 50\n",
    "3. Per ogni query $q \\in Q$ (min 5):\n",
    "    1. Fare il ranking a mano delle tabelle\n",
    "        - Salviamo i ranking per ogni query in un json, con le informazioni rilevanti, tipo il ranking, il valore di rilevanza per ogni elemento etc.\n",
    "    2. Interrogare ogni sistema sulla query\n",
    "    3. Calcolare le metriche: \n",
    "        - Reciprocal Rank: $\\text{RR}_q = \\frac{1}{rank_i}$ dove $i$ è l’elemento più rilevante.\n",
    "            - nella pratica possiamo controllare se l’elemento scelto dal motore ha almeno lo score massimo (potrebbero esserci dei parimerito)\n",
    "        - Normalized Discounted Cumulative Gain con taglio $\\text{K} = \\set{5,15}$:\n",
    "            \n",
    "            $$\n",
    "            \\text{NDCG@K}_q = \\frac{\\text{DCG@K}_q}{\\text{IDCG@K}_q}\n",
    "            $$\n",
    "            \n",
    "            - dove dividiamo il $\\text{DCG@K}_q = rel_1 + \\sum_{i=2}^K \\frac{rel_i}{\\log_2 (i + 1)}$ con quello ideale, cioè dove il ranking è il migliore possibile\n",
    "4. Calcolare la media delle metriche:\n",
    "    - Mean Reciprocal Rank: $\\text{MRR} = \\frac{1}{|Q|} \\sum_{q \\in Q} \\text{RR}_q$\n",
    "    - Media dei NDCG: $\\frac{1}{|Q|} \\sum_{q \\in Q} \\text{NDCG@K}_q$\n",
    "\n",
    "### Query (in verde stesso ranking ma proviamo sinonimi)\n",
    "\n",
    "1. NDCG su dataset movielens ✅\n",
    "2. Recommender systems Recall su dataset goodbook ✅\n",
    "3. Recommender systems MRR ✅\n",
    "4. Deep Learning dataset Apple Flower ✅\n",
    "5. Deep Learning GPT3 precision f1 ✅\n",
    "6. Deep Learning GPT3 precision f-measure ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results_file = \"./results_hybrid.json\"\n",
    "ground_truth_path = \"./ground_truth\"\n",
    "num_queries = 6\n",
    "\n",
    "# model -> method -> query -> (position, id) \n",
    "results: dict[str, dict[str, dict[str, dict[str, str]]]] = {}\n",
    "\n",
    "# query -> (position, table[table_id, query_id, rel]) \n",
    "ground_truth: dict[str, dict[str, dict[str, str]]] = {}\n",
    "\n",
    "with open(results_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    results = json.load(file)\n",
    "    \n",
    "for i in range(1, num_queries + 1):\n",
    "    query_id = f\"q{i}\"\n",
    "    with open(ground_truth_path + f\"/{query_id}_rank.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        ground_truth[query_id] = json.load(file)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR value for lucene using method: bm25 is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for bert-base-uncased using method: tab_embedding is 0.03333333333333333 --- best not found in 5/6 queries.\n",
      "MRR value for bert-base-uncased using method: tab_cap_embedding is 0.027777777777777776 --- best not found in 5/6 queries.\n",
      "MRR value for bert-base-uncased using method: tab_cap_ref_embedding is 0.023809523809523808 --- best not found in 5/6 queries.\n",
      "MRR value for bert-base-uncased using method: weighted_embedding is 0.023809523809523808 --- best not found in 5/6 queries.\n",
      "MRR value for distilbert-base-uncased using method: tab_embedding is 0.03333333333333333 --- best not found in 5/6 queries.\n",
      "MRR value for distilbert-base-uncased using method: tab_cap_embedding is 0.020833333333333332 --- best not found in 5/6 queries.\n",
      "MRR value for distilbert-base-uncased using method: tab_cap_ref_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for distilbert-base-uncased using method: weighted_embedding is 0.018518518518518517 --- best not found in 5/6 queries.\n",
      "MRR value for allenai/scibert_scivocab_uncased using method: tab_embedding is 0.016666666666666666 --- best not found in 5/6 queries.\n",
      "MRR value for allenai/scibert_scivocab_uncased using method: tab_cap_embedding is 0.011111111111111112 --- best not found in 5/6 queries.\n",
      "MRR value for allenai/scibert_scivocab_uncased using method: tab_cap_ref_embedding is 0.011904761904761904 --- best not found in 5/6 queries.\n",
      "MRR value for allenai/scibert_scivocab_uncased using method: weighted_embedding is 0.011904761904761904 --- best not found in 5/6 queries.\n",
      "MRR value for all-mpnet-base-v2 using method: tab_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for all-mpnet-base-v2 using method: tab_cap_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for all-mpnet-base-v2 using method: tab_cap_ref_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for all-mpnet-base-v2 using method: weighted_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/sentence-t5-large using method: tab_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/sentence-t5-large using method: tab_cap_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/sentence-t5-large using method: tab_cap_ref_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/sentence-t5-large using method: weighted_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/all-MiniLM-L6-v2 using method: tab_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/all-MiniLM-L6-v2 using method: tab_cap_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/all-MiniLM-L6-v2 using method: tab_cap_ref_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for sentence-transformers/all-MiniLM-L6-v2 using method: weighted_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for deepset/sentence_bert using method: tab_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for deepset/sentence_bert using method: tab_cap_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for deepset/sentence_bert using method: tab_cap_ref_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n",
      "MRR value for deepset/sentence_bert using method: weighted_embedding is 0.041666666666666664 --- best not found in 5/6 queries.\n"
     ]
    }
   ],
   "source": [
    "mrr_values: dict[str, dict[str, float]] = {}\n",
    "\n",
    "for model, methods in results.items():\n",
    "    mrr_values[model] = {}\n",
    "    for method, queries in methods.items():\n",
    "        sum_rr = 0\n",
    "        not_founds = 0\n",
    "        \n",
    "        for query_id, ranking in queries.items():\n",
    "            best_tables_ids: list[str] = []\n",
    "            best_table =  ground_truth[query_id][\"1\"]\n",
    "            \n",
    "            # this checks for equal relevance tables other than the first position\n",
    "            for pos, table in ground_truth[query_id].items():\n",
    "                if table[\"rel\"] == best_table[\"rel\"]:\n",
    "                    best_tables_ids.append(table[\"paper_id\"] + \"#\" + table[\"table_id\"])\n",
    "            \n",
    "            rr = 0\n",
    "            for pos, table_id in ranking.items():\n",
    "                if (table_id in best_tables_ids): rr = 1.0 / float(pos)\n",
    "            \n",
    "            if rr == 0: not_founds += 1\n",
    "            sum_rr += rr\n",
    "            \n",
    "        mrr = sum_rr / num_queries\n",
    "        mrr_values[model][method] = mrr\n",
    "        print(f\"MRR value for {model} using method: {method} is {mrr} --- best not found in {not_founds}/{num_queries} queries.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 for query q1 using lucene with method bm25 is 0.09211555444482922.\n",
      "NDCG@5 for query q2 using lucene with method bm25 is 0.179496619120427.\n",
      "NDCG@5 for query q3 using lucene with method bm25 is 0.03993976893994232.\n",
      "NDCG@5 for query q4 using lucene with method bm25 is 0.9169165661407997.\n",
      "NDCG@5 for query q5 using lucene with method bm25 is 0.17308207417558696.\n",
      "NDCG@5 for query q6 using lucene with method bm25 is 0.20632150354878148.\n",
      "Average NDCG@5 for lucene with method bm25 is 0.20632150354878148.\n",
      "NDCG@5 for query q1 using bert-base-uncased with method tab_embedding is 0.12038834766321689.\n",
      "NDCG@5 for query q2 using bert-base-uncased with method tab_embedding is 0.1367281413114968.\n",
      "NDCG@5 for query q3 using bert-base-uncased with method tab_embedding is 0.08984623471541199.\n",
      "NDCG@5 for query q4 using bert-base-uncased with method tab_embedding is 0.9649814899835472.\n",
      "NDCG@5 for query q5 using bert-base-uncased with method tab_embedding is 0.0.\n",
      "NDCG@5 for query q6 using bert-base-uncased with method tab_embedding is 0.0.\n",
      "Average NDCG@5 for bert-base-uncased with method tab_embedding is 0.0.\n",
      "NDCG@5 for query q1 using bert-base-uncased with method tab_cap_embedding is 0.15266621562221735.\n",
      "NDCG@5 for query q2 using bert-base-uncased with method tab_cap_embedding is 0.12575032171241649.\n",
      "NDCG@5 for query q3 using bert-base-uncased with method tab_cap_embedding is 0.1490233907164942.\n",
      "NDCG@5 for query q4 using bert-base-uncased with method tab_cap_embedding is 0.8654465132941629.\n",
      "NDCG@5 for query q5 using bert-base-uncased with method tab_cap_embedding is 0.02883715054163623.\n",
      "NDCG@5 for query q6 using bert-base-uncased with method tab_cap_embedding is 0.03755453075175523.\n",
      "Average NDCG@5 for bert-base-uncased with method tab_cap_embedding is 0.03755453075175523.\n",
      "NDCG@5 for query q1 using bert-base-uncased with method tab_cap_ref_embedding is 0.22261285266497685.\n",
      "NDCG@5 for query q2 using bert-base-uncased with method tab_cap_ref_embedding is 0.22833120928917078.\n",
      "NDCG@5 for query q3 using bert-base-uncased with method tab_cap_ref_embedding is 0.1002065483545423.\n",
      "NDCG@5 for query q4 using bert-base-uncased with method tab_cap_ref_embedding is 0.8820729545522511.\n",
      "NDCG@5 for query q5 using bert-base-uncased with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q6 using bert-base-uncased with method tab_cap_ref_embedding is 0.028165898063816423.\n",
      "Average NDCG@5 for bert-base-uncased with method tab_cap_ref_embedding is 0.028165898063816423.\n",
      "NDCG@5 for query q1 using bert-base-uncased with method weighted_embedding is 0.21301798490618176.\n",
      "NDCG@5 for query q2 using bert-base-uncased with method weighted_embedding is 0.13639366180095228.\n",
      "NDCG@5 for query q3 using bert-base-uncased with method weighted_embedding is 0.061029519393822854.\n",
      "NDCG@5 for query q4 using bert-base-uncased with method weighted_embedding is 0.8036663262866925.\n",
      "NDCG@5 for query q5 using bert-base-uncased with method weighted_embedding is 0.02883715054163623.\n",
      "NDCG@5 for query q6 using bert-base-uncased with method weighted_embedding is 0.03044600124221507.\n",
      "Average NDCG@5 for bert-base-uncased with method weighted_embedding is 0.03044600124221507.\n",
      "NDCG@5 for query q1 using distilbert-base-uncased with method tab_embedding is 0.11419387050153543.\n",
      "NDCG@5 for query q2 using distilbert-base-uncased with method tab_embedding is 0.1149151952813337.\n",
      "NDCG@5 for query q3 using distilbert-base-uncased with method tab_embedding is 0.04003584886000494.\n",
      "NDCG@5 for query q4 using distilbert-base-uncased with method tab_embedding is 1.\n",
      "NDCG@5 for query q5 using distilbert-base-uncased with method tab_embedding is 0.03755453075175523.\n",
      "NDCG@5 for query q6 using distilbert-base-uncased with method tab_embedding is 0.040131581286733345.\n",
      "Average NDCG@5 for distilbert-base-uncased with method tab_embedding is 0.040131581286733345.\n",
      "NDCG@5 for query q1 using distilbert-base-uncased with method tab_cap_embedding is 0.15168731162177831.\n",
      "NDCG@5 for query q2 using distilbert-base-uncased with method tab_cap_embedding is 0.17430745896088673.\n",
      "NDCG@5 for query q3 using distilbert-base-uncased with method tab_cap_embedding is 0.0679449959305275.\n",
      "NDCG@5 for query q4 using distilbert-base-uncased with method tab_cap_embedding is 0.8039971958825866.\n",
      "NDCG@5 for query q5 using distilbert-base-uncased with method tab_cap_embedding is 0.0.\n",
      "NDCG@5 for query q6 using distilbert-base-uncased with method tab_cap_embedding is 0.08592283624909834.\n",
      "Average NDCG@5 for distilbert-base-uncased with method tab_cap_embedding is 0.08592283624909834.\n",
      "NDCG@5 for query q1 using distilbert-base-uncased with method tab_cap_ref_embedding is 0.15168731162177831.\n",
      "NDCG@5 for query q2 using distilbert-base-uncased with method tab_cap_ref_embedding is 0.3009208026430688.\n",
      "NDCG@5 for query q3 using distilbert-base-uncased with method tab_cap_ref_embedding is 0.07528614265368991.\n",
      "NDCG@5 for query q4 using distilbert-base-uncased with method tab_cap_ref_embedding is 0.5589706312121682.\n",
      "NDCG@5 for query q5 using distilbert-base-uncased with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q6 using distilbert-base-uncased with method tab_cap_ref_embedding is 0.0.\n",
      "Average NDCG@5 for distilbert-base-uncased with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q1 using distilbert-base-uncased with method weighted_embedding is 0.10142499232330955.\n",
      "NDCG@5 for query q2 using distilbert-base-uncased with method weighted_embedding is 0.13114646220788528.\n",
      "NDCG@5 for query q3 using distilbert-base-uncased with method weighted_embedding is 0.057463028648630655.\n",
      "NDCG@5 for query q4 using distilbert-base-uncased with method weighted_embedding is 0.6979330800692278.\n",
      "NDCG@5 for query q5 using distilbert-base-uncased with method weighted_embedding is 0.0.\n",
      "NDCG@5 for query q6 using distilbert-base-uncased with method weighted_embedding is 0.03755453075175523.\n",
      "Average NDCG@5 for distilbert-base-uncased with method weighted_embedding is 0.03755453075175523.\n",
      "NDCG@5 for query q1 using allenai/scibert_scivocab_uncased with method tab_embedding is 0.05300306015832782.\n",
      "NDCG@5 for query q2 using allenai/scibert_scivocab_uncased with method tab_embedding is 0.06487825028923273.\n",
      "NDCG@5 for query q3 using allenai/scibert_scivocab_uncased with method tab_embedding is 0.0.\n",
      "NDCG@5 for query q4 using allenai/scibert_scivocab_uncased with method tab_embedding is 0.7411304865761499.\n",
      "NDCG@5 for query q5 using allenai/scibert_scivocab_uncased with method tab_embedding is 0.07896756937489709.\n",
      "NDCG@5 for query q6 using allenai/scibert_scivocab_uncased with method tab_embedding is 0.03391512068809118.\n",
      "Average NDCG@5 for allenai/scibert_scivocab_uncased with method tab_embedding is 0.03391512068809118.\n",
      "NDCG@5 for query q1 using allenai/scibert_scivocab_uncased with method tab_cap_embedding is 0.09020228417231749.\n",
      "NDCG@5 for query q2 using allenai/scibert_scivocab_uncased with method tab_cap_embedding is 0.06487825028923273.\n",
      "NDCG@5 for query q3 using allenai/scibert_scivocab_uncased with method tab_cap_embedding is 0.0.\n",
      "NDCG@5 for query q4 using allenai/scibert_scivocab_uncased with method tab_cap_embedding is 0.35656477722179697.\n",
      "NDCG@5 for query q5 using allenai/scibert_scivocab_uncased with method tab_cap_embedding is 0.0637073043128614.\n",
      "NDCG@5 for query q6 using allenai/scibert_scivocab_uncased with method tab_cap_embedding is 0.03554140624904497.\n",
      "Average NDCG@5 for allenai/scibert_scivocab_uncased with method tab_cap_embedding is 0.03554140624904497.\n",
      "NDCG@5 for query q1 using allenai/scibert_scivocab_uncased with method tab_cap_ref_embedding is 0.13249643973411912.\n",
      "NDCG@5 for query q2 using allenai/scibert_scivocab_uncased with method tab_cap_ref_embedding is 0.1499572356513246.\n",
      "NDCG@5 for query q3 using allenai/scibert_scivocab_uncased with method tab_cap_ref_embedding is 0.03607940910642519.\n",
      "NDCG@5 for query q4 using allenai/scibert_scivocab_uncased with method tab_cap_ref_embedding is 0.29493520747721436.\n",
      "NDCG@5 for query q5 using allenai/scibert_scivocab_uncased with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q6 using allenai/scibert_scivocab_uncased with method tab_cap_ref_embedding is 0.0.\n",
      "Average NDCG@5 for allenai/scibert_scivocab_uncased with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q1 using allenai/scibert_scivocab_uncased with method weighted_embedding is 0.12341901287067016.\n",
      "NDCG@5 for query q2 using allenai/scibert_scivocab_uncased with method weighted_embedding is 0.06071209176132089.\n",
      "NDCG@5 for query q3 using allenai/scibert_scivocab_uncased with method weighted_embedding is 0.0.\n",
      "NDCG@5 for query q4 using allenai/scibert_scivocab_uncased with method weighted_embedding is 0.6444971443161073.\n",
      "NDCG@5 for query q5 using allenai/scibert_scivocab_uncased with method weighted_embedding is 0.07749934762516848.\n",
      "NDCG@5 for query q6 using allenai/scibert_scivocab_uncased with method weighted_embedding is 0.03391512068809118.\n",
      "Average NDCG@5 for allenai/scibert_scivocab_uncased with method weighted_embedding is 0.03391512068809118.\n",
      "NDCG@5 for query q1 using all-mpnet-base-v2 with method tab_embedding is 0.0.\n",
      "NDCG@5 for query q2 using all-mpnet-base-v2 with method tab_embedding is 0.0.\n",
      "NDCG@5 for query q3 using all-mpnet-base-v2 with method tab_embedding is 0.04704533245264237.\n",
      "NDCG@5 for query q4 using all-mpnet-base-v2 with method tab_embedding is 1.0.\n",
      "NDCG@5 for query q5 using all-mpnet-base-v2 with method tab_embedding is 0.1258654261619446.\n",
      "NDCG@5 for query q6 using all-mpnet-base-v2 with method tab_embedding is 0.10892606191649011.\n",
      "Average NDCG@5 for all-mpnet-base-v2 with method tab_embedding is 0.10892606191649011.\n",
      "NDCG@5 for query q1 using all-mpnet-base-v2 with method tab_cap_embedding is 0.10701186458952612.\n",
      "NDCG@5 for query q2 using all-mpnet-base-v2 with method tab_cap_embedding is 0.06080770600160857.\n",
      "NDCG@5 for query q3 using all-mpnet-base-v2 with method tab_cap_embedding is 0.13347863009960706.\n",
      "NDCG@5 for query q4 using all-mpnet-base-v2 with method tab_cap_embedding is 0.9169165661407997.\n",
      "NDCG@5 for query q5 using all-mpnet-base-v2 with method tab_cap_embedding is 0.0.\n",
      "NDCG@5 for query q6 using all-mpnet-base-v2 with method tab_cap_embedding is 0.05775693818528191.\n",
      "Average NDCG@5 for all-mpnet-base-v2 with method tab_cap_embedding is 0.05775693818528191.\n",
      "NDCG@5 for query q1 using all-mpnet-base-v2 with method tab_cap_ref_embedding is 0.10261662111048199.\n",
      "NDCG@5 for query q2 using all-mpnet-base-v2 with method tab_cap_ref_embedding is 0.06626821191865256.\n",
      "NDCG@5 for query q3 using all-mpnet-base-v2 with method tab_cap_ref_embedding is 0.06782847368625021.\n",
      "NDCG@5 for query q4 using all-mpnet-base-v2 with method tab_cap_ref_embedding is 1.0.\n",
      "NDCG@5 for query q5 using all-mpnet-base-v2 with method tab_cap_ref_embedding is 0.1322912753694891.\n",
      "NDCG@5 for query q6 using all-mpnet-base-v2 with method tab_cap_ref_embedding is 0.26891535142262474.\n",
      "Average NDCG@5 for all-mpnet-base-v2 with method tab_cap_ref_embedding is 0.26891535142262474.\n",
      "NDCG@5 for query q1 using all-mpnet-base-v2 with method weighted_embedding is 0.0656140243656653.\n",
      "NDCG@5 for query q2 using all-mpnet-base-v2 with method weighted_embedding is 0.0.\n",
      "NDCG@5 for query q3 using all-mpnet-base-v2 with method weighted_embedding is 0.11464165666860512.\n",
      "NDCG@5 for query q4 using all-mpnet-base-v2 with method weighted_embedding is 1.0.\n",
      "NDCG@5 for query q5 using all-mpnet-base-v2 with method weighted_embedding is 0.0.\n",
      "NDCG@5 for query q6 using all-mpnet-base-v2 with method weighted_embedding is 0.0.\n",
      "Average NDCG@5 for all-mpnet-base-v2 with method weighted_embedding is 0.0.\n",
      "NDCG@5 for query q1 using sentence-transformers/sentence-t5-large with method tab_embedding is 0.0.\n",
      "NDCG@5 for query q2 using sentence-transformers/sentence-t5-large with method tab_embedding is 0.05482848215898497.\n",
      "NDCG@5 for query q3 using sentence-transformers/sentence-t5-large with method tab_embedding is 0.06330303605727612.\n",
      "NDCG@5 for query q4 using sentence-transformers/sentence-t5-large with method tab_embedding is 1.\n",
      "NDCG@5 for query q5 using sentence-transformers/sentence-t5-large with method tab_embedding is 0.06140423226925394.\n",
      "NDCG@5 for query q6 using sentence-transformers/sentence-t5-large with method tab_embedding is 0.1240308373826199.\n",
      "Average NDCG@5 for sentence-transformers/sentence-t5-large with method tab_embedding is 0.1240308373826199.\n",
      "NDCG@5 for query q1 using sentence-transformers/sentence-t5-large with method tab_cap_embedding is 0.0.\n",
      "NDCG@5 for query q2 using sentence-transformers/sentence-t5-large with method tab_cap_embedding is 0.0.\n",
      "NDCG@5 for query q3 using sentence-transformers/sentence-t5-large with method tab_cap_embedding is 0.08617638746139053.\n",
      "NDCG@5 for query q4 using sentence-transformers/sentence-t5-large with method tab_cap_embedding is 0.938467058788701.\n",
      "NDCG@5 for query q5 using sentence-transformers/sentence-t5-large with method tab_cap_embedding is 0.17461257648907486.\n",
      "NDCG@5 for query q6 using sentence-transformers/sentence-t5-large with method tab_cap_embedding is 0.2578985770518536.\n",
      "Average NDCG@5 for sentence-transformers/sentence-t5-large with method tab_cap_embedding is 0.2578985770518536.\n",
      "NDCG@5 for query q1 using sentence-transformers/sentence-t5-large with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q2 using sentence-transformers/sentence-t5-large with method tab_cap_ref_embedding is 0.1965086264174656.\n",
      "NDCG@5 for query q3 using sentence-transformers/sentence-t5-large with method tab_cap_ref_embedding is 0.06330303605727612.\n",
      "NDCG@5 for query q4 using sentence-transformers/sentence-t5-large with method tab_cap_ref_embedding is 1.0.\n",
      "NDCG@5 for query q5 using sentence-transformers/sentence-t5-large with method tab_cap_ref_embedding is 0.11287930257395978.\n",
      "NDCG@5 for query q6 using sentence-transformers/sentence-t5-large with method tab_cap_ref_embedding is 0.17328321767889168.\n",
      "Average NDCG@5 for sentence-transformers/sentence-t5-large with method tab_cap_ref_embedding is 0.17328321767889168.\n",
      "NDCG@5 for query q1 using sentence-transformers/sentence-t5-large with method weighted_embedding is 0.0.\n",
      "NDCG@5 for query q2 using sentence-transformers/sentence-t5-large with method weighted_embedding is 0.10231542279078923.\n",
      "NDCG@5 for query q3 using sentence-transformers/sentence-t5-large with method weighted_embedding is 0.10737682698668063.\n",
      "NDCG@5 for query q4 using sentence-transformers/sentence-t5-large with method weighted_embedding is 1.\n",
      "NDCG@5 for query q5 using sentence-transformers/sentence-t5-large with method weighted_embedding is 0.10813211328070366.\n",
      "NDCG@5 for query q6 using sentence-transformers/sentence-t5-large with method weighted_embedding is 0.15103109492209363.\n",
      "Average NDCG@5 for sentence-transformers/sentence-t5-large with method weighted_embedding is 0.15103109492209363.\n",
      "NDCG@5 for query q1 using sentence-transformers/all-MiniLM-L6-v2 with method tab_embedding is 0.02956965945817601.\n",
      "NDCG@5 for query q2 using sentence-transformers/all-MiniLM-L6-v2 with method tab_embedding is 0.049220170887004325.\n",
      "NDCG@5 for query q3 using sentence-transformers/all-MiniLM-L6-v2 with method tab_embedding is 0.058797442018233385.\n",
      "NDCG@5 for query q4 using sentence-transformers/all-MiniLM-L6-v2 with method tab_embedding is 1.0.\n",
      "NDCG@5 for query q5 using sentence-transformers/all-MiniLM-L6-v2 with method tab_embedding is 0.13554418083035452.\n",
      "NDCG@5 for query q6 using sentence-transformers/all-MiniLM-L6-v2 with method tab_embedding is 0.07581740640985336.\n",
      "Average NDCG@5 for sentence-transformers/all-MiniLM-L6-v2 with method tab_embedding is 0.07581740640985336.\n",
      "NDCG@5 for query q1 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_embedding is 0.09426092267803873.\n",
      "NDCG@5 for query q2 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_embedding is 0.04553406882099067.\n",
      "NDCG@5 for query q3 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_embedding is 0.11786554659284121.\n",
      "NDCG@5 for query q4 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_embedding is 0.9169165661407997.\n",
      "NDCG@5 for query q5 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_embedding is 0.10552461673813467.\n",
      "NDCG@5 for query q6 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_embedding is 0.08113875768883252.\n",
      "Average NDCG@5 for sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_embedding is 0.08113875768883252.\n",
      "NDCG@5 for query q1 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_ref_embedding is 0.05653659750221634.\n",
      "NDCG@5 for query q2 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q3 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_ref_embedding is 0.05869472667219029.\n",
      "NDCG@5 for query q4 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_ref_embedding is 1.\n",
      "NDCG@5 for query q5 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_ref_embedding is 0.16273166796474464.\n",
      "NDCG@5 for query q6 using sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_ref_embedding is 0.12509410172174038.\n",
      "Average NDCG@5 for sentence-transformers/all-MiniLM-L6-v2 with method tab_cap_ref_embedding is 0.12509410172174038.\n",
      "NDCG@5 for query q1 using sentence-transformers/all-MiniLM-L6-v2 with method weighted_embedding is 0.07616134238675033.\n",
      "NDCG@5 for query q2 using sentence-transformers/all-MiniLM-L6-v2 with method weighted_embedding is 0.05482848215898497.\n",
      "NDCG@5 for query q3 using sentence-transformers/all-MiniLM-L6-v2 with method weighted_embedding is 0.11786554659284121.\n",
      "NDCG@5 for query q4 using sentence-transformers/all-MiniLM-L6-v2 with method weighted_embedding is 0.9885057531265261.\n",
      "NDCG@5 for query q5 using sentence-transformers/all-MiniLM-L6-v2 with method weighted_embedding is 0.0789641818858686.\n",
      "NDCG@5 for query q6 using sentence-transformers/all-MiniLM-L6-v2 with method weighted_embedding is 0.07958630144868735.\n",
      "Average NDCG@5 for sentence-transformers/all-MiniLM-L6-v2 with method weighted_embedding is 0.07958630144868735.\n",
      "NDCG@5 for query q1 using deepset/sentence_bert with method tab_embedding is 0.06688241536845382.\n",
      "NDCG@5 for query q2 using deepset/sentence_bert with method tab_embedding is 0.0.\n",
      "NDCG@5 for query q3 using deepset/sentence_bert with method tab_embedding is 0.08948910871072548.\n",
      "NDCG@5 for query q4 using deepset/sentence_bert with method tab_embedding is 1.0.\n",
      "NDCG@5 for query q5 using deepset/sentence_bert with method tab_embedding is 0.0789098582106432.\n",
      "NDCG@5 for query q6 using deepset/sentence_bert with method tab_embedding is 0.10403673316746412.\n",
      "Average NDCG@5 for deepset/sentence_bert with method tab_embedding is 0.10403673316746412.\n",
      "NDCG@5 for query q1 using deepset/sentence_bert with method tab_cap_embedding is 0.1399293770207598.\n",
      "NDCG@5 for query q2 using deepset/sentence_bert with method tab_cap_embedding is 0.0466192412678999.\n",
      "NDCG@5 for query q3 using deepset/sentence_bert with method tab_cap_embedding is 0.13960401225606908.\n",
      "NDCG@5 for query q4 using deepset/sentence_bert with method tab_cap_embedding is 0.9169165661407997.\n",
      "NDCG@5 for query q5 using deepset/sentence_bert with method tab_cap_embedding is 0.0.\n",
      "NDCG@5 for query q6 using deepset/sentence_bert with method tab_cap_embedding is 0.02883715054163623.\n",
      "Average NDCG@5 for deepset/sentence_bert with method tab_cap_embedding is 0.02883715054163623.\n",
      "NDCG@5 for query q1 using deepset/sentence_bert with method tab_cap_ref_embedding is 0.16001492474785395.\n",
      "NDCG@5 for query q2 using deepset/sentence_bert with method tab_cap_ref_embedding is 0.0.\n",
      "NDCG@5 for query q3 using deepset/sentence_bert with method tab_cap_ref_embedding is 0.07023445402629847.\n",
      "NDCG@5 for query q4 using deepset/sentence_bert with method tab_cap_ref_embedding is 1.0.\n",
      "NDCG@5 for query q5 using deepset/sentence_bert with method tab_cap_ref_embedding is 0.058611899306031494.\n",
      "NDCG@5 for query q6 using deepset/sentence_bert with method tab_cap_ref_embedding is 0.10030680198148265.\n",
      "Average NDCG@5 for deepset/sentence_bert with method tab_cap_ref_embedding is 0.10030680198148265.\n",
      "NDCG@5 for query q1 using deepset/sentence_bert with method weighted_embedding is 0.14234723802841134.\n",
      "NDCG@5 for query q2 using deepset/sentence_bert with method weighted_embedding is 0.049220170887004325.\n",
      "NDCG@5 for query q3 using deepset/sentence_bert with method weighted_embedding is 0.07102948138578559.\n",
      "NDCG@5 for query q4 using deepset/sentence_bert with method weighted_embedding is 1.0.\n",
      "NDCG@5 for query q5 using deepset/sentence_bert with method weighted_embedding is 0.0.\n",
      "NDCG@5 for query q6 using deepset/sentence_bert with method weighted_embedding is 0.06810848797666268.\n",
      "Average NDCG@5 for deepset/sentence_bert with method weighted_embedding is 0.06810848797666268.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "K = 5\n",
    "idcg_values: dict[str, float] = {}\n",
    "\n",
    "for query_id, ranking in ground_truth.items():    \n",
    "    idcg = 0\n",
    "\n",
    "    for i in range(1, K + 1):\n",
    "        table = ground_truth[query_id][str(i)]\n",
    "        table_id = table[\"paper_id\"] + \"#\" + table[\"table_id\"]\n",
    "        rel = float(table[\"rel\"])\n",
    "\n",
    "        idcg += rel / math.log2(i + 1)\n",
    "    \n",
    "    idcg_values[query_id] = idcg\n",
    "\n",
    "for model, methods in results.items():\n",
    "    for method, queries in methods.items():\n",
    "        sum_ndcg: float = 0\n",
    "        for query_id, ranking in queries.items():\n",
    "            dcg = 0\n",
    "            for pos, table_id in ranking.items():\n",
    "                rel: float = 0\n",
    "                \n",
    "                for _, gt_table in ground_truth[query_id].items():\n",
    "                   gt_table_id = gt_table[\"paper_id\"] + \"#\" + gt_table[\"table_id\"]\n",
    "                   if table_id == gt_table_id:\n",
    "                       rel = float(gt_table[\"rel\"])\n",
    "                \n",
    "                dcg += rel / math.log2(int(pos) + 1)\n",
    "                \n",
    "            ndcg = dcg / idcg_values[query_id] if dcg / idcg_values[query_id] <= 1 else 1\n",
    "            sum_ndcg += ndcg\n",
    "            \n",
    "            print(f\"NDCG@{K} for query {query_id} using {model} with method {method} is {ndcg}.\")\n",
    "        print(f\"Average NDCG@{K} for {model} with method {method} is {ndcg}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Precision@15 of lucene with bm25 for query q1 is: 0.08677082177082177\n",
      "Avg Precision@15 of lucene with bm25 for query q2 is: 0.17909719909719907\n",
      "Avg Precision@15 of lucene with bm25 for query q3 is: 0.15454859954859962\n",
      "Avg Precision@15 of lucene with bm25 for query q4 is: 0.5959721759721762\n",
      "Avg Precision@15 of lucene with bm25 for query q5 is: 0.15808210308210308\n",
      "Avg Precision@15 of lucene with bm25 for query q6 is: 0.2342220742220742\n",
      "Avg Precision@15 of bert-base-uncased with tab_embedding for query q1 is: 0.20290672290672288\n",
      "Avg Precision@15 of bert-base-uncased with tab_embedding for query q2 is: 0.10827709327709328\n",
      "Avg Precision@15 of bert-base-uncased with tab_embedding for query q3 is: 0.22941465941465944\n",
      "Avg Precision@15 of bert-base-uncased with tab_embedding for query q4 is: 0.6482985532985533\n",
      "Avg Precision@15 of bert-base-uncased with tab_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of bert-base-uncased with tab_embedding for query q6 is: 0.0\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_embedding for query q1 is: 0.25354164354164355\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_embedding for query q2 is: 0.0743088393088393\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_embedding for query q3 is: 0.4241219891219891\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_embedding for query q4 is: 0.5437499537499537\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_embedding for query q5 is: 0.009206349206349208\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_embedding for query q6 is: 0.057881932881932885\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_ref_embedding for query q1 is: 0.3424305324305325\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_ref_embedding for query q2 is: 0.25354164354164355\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_ref_embedding for query q3 is: 0.26274799274799276\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_ref_embedding for query q4 is: 0.5548610648610649\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_ref_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of bert-base-uncased with tab_cap_ref_embedding for query q6 is: 0.0044444444444444444\n",
      "Avg Precision@15 of bert-base-uncased with weighted_embedding for query q1 is: 0.3757638657638659\n",
      "Avg Precision@15 of bert-base-uncased with weighted_embedding for query q2 is: 0.10901783401783402\n",
      "Avg Precision@15 of bert-base-uncased with weighted_embedding for query q3 is: 0.06435934435934436\n",
      "Avg Precision@15 of bert-base-uncased with weighted_embedding for query q4 is: 0.45152773152773146\n",
      "Avg Precision@15 of bert-base-uncased with weighted_embedding for query q5 is: 0.009206349206349208\n",
      "Avg Precision@15 of bert-base-uncased with weighted_embedding for query q6 is: 0.019890109890109888\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_embedding for query q1 is: 0.18049931549931547\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_embedding for query q2 is: 0.15454859954859962\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_embedding for query q3 is: 0.013650793650793651\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_embedding for query q4 is: 0.6575049025049025\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_embedding for query q5 is: 0.057881932881932885\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_embedding for query q6 is: 0.068993043993044\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_embedding for query q1 is: 0.27576386576386575\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_embedding for query q2 is: 0.15899304399304404\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_embedding for query q3 is: 0.12816720316720315\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_embedding for query q4 is: 0.4897816997816998\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_embedding for query q6 is: 0.13554982054982054\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_ref_embedding for query q1 is: 0.27576386576386575\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_ref_embedding for query q2 is: 0.3424305324305325\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_ref_embedding for query q3 is: 0.17282569282569285\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_ref_embedding for query q4 is: 0.37475690975690973\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_ref_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of distilbert-base-uncased with tab_cap_ref_embedding for query q6 is: 0.0\n",
      "Avg Precision@15 of distilbert-base-uncased with weighted_embedding for query q1 is: 0.1513194213194213\n",
      "Avg Precision@15 of distilbert-base-uncased with weighted_embedding for query q2 is: 0.09494375994375993\n",
      "Avg Precision@15 of distilbert-base-uncased with weighted_embedding for query q3 is: 0.03354090354090354\n",
      "Avg Precision@15 of distilbert-base-uncased with weighted_embedding for query q4 is: 0.3674801124801124\n",
      "Avg Precision@15 of distilbert-base-uncased with weighted_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of distilbert-base-uncased with weighted_embedding for query q6 is: 0.057881932881932885\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_embedding for query q1 is: 0.1212152662152662\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_embedding for query q2 is: 0.068993043993044\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_embedding for query q3 is: 0.0\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_embedding for query q4 is: 0.4484060384060384\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_embedding for query q5 is: 0.11888315388315389\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_embedding for query q6 is: 0.04002479002479002\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_embedding for query q1 is: 0.11332759832759833\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_embedding for query q2 is: 0.068993043993044\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_embedding for query q3 is: 0.0\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_embedding for query q4 is: 0.15179561179561182\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_embedding for query q5 is: 0.052802567802567806\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_embedding for query q6 is: 0.04835812335812337\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_ref_embedding for query q1 is: 0.23687497687497686\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_ref_embedding for query q2 is: 0.13901783401783402\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_ref_embedding for query q3 is: 0.013650793650793651\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_ref_embedding for query q4 is: 0.06777444777444777\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_ref_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with tab_cap_ref_embedding for query q6 is: 0.0\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with weighted_embedding for query q1 is: 0.21243053243053242\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with weighted_embedding for query q2 is: 0.057881932881932885\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with weighted_embedding for query q3 is: 0.0\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with weighted_embedding for query q4 is: 0.3611061161061161\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with weighted_embedding for query q5 is: 0.12235116735116737\n",
      "Avg Precision@15 of allenai/scibert_scivocab_uncased with weighted_embedding for query q6 is: 0.04002479002479002\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_embedding for query q1 is: 0.0\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_embedding for query q2 is: 0.0\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_embedding for query q3 is: 0.10343748843748843\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_embedding for query q5 is: 0.09975450475450474\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_embedding for query q6 is: 0.14830188330188332\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_embedding for query q1 is: 0.15454859954859962\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_embedding for query q2 is: 0.009206349206349208\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_embedding for query q3 is: 0.4247569097569098\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_embedding for query q4 is: 0.5959721759721762\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_embedding for query q6 is: 0.01877899877899878\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_ref_embedding for query q1 is: 0.12494375994375995\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_ref_embedding for query q2 is: 0.02595071595071595\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_ref_embedding for query q3 is: 0.11777204277204277\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_ref_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_ref_embedding for query q5 is: 0.132005587005587\n",
      "Avg Precision@15 of all-mpnet-base-v2 with tab_cap_ref_embedding for query q6 is: 0.5061854811854811\n",
      "Avg Precision@15 of all-mpnet-base-v2 with weighted_embedding for query q1 is: 0.08232637732637732\n",
      "Avg Precision@15 of all-mpnet-base-v2 with weighted_embedding for query q2 is: 0.0\n",
      "Avg Precision@15 of all-mpnet-base-v2 with weighted_embedding for query q3 is: 0.32745532245532244\n",
      "Avg Precision@15 of all-mpnet-base-v2 with weighted_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of all-mpnet-base-v2 with weighted_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of all-mpnet-base-v2 with weighted_embedding for query q6 is: 0.0\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_embedding for query q1 is: 0.0\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_embedding for query q2 is: 0.04002479002479002\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_embedding for query q3 is: 0.22121526621526624\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_embedding for query q4 is: 0.7042492692492692\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_embedding for query q5 is: 0.04182373182373182\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_embedding for query q6 is: 0.09279276279276279\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_embedding for query q1 is: 0.0\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_embedding for query q2 is: 0.0\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_embedding for query q3 is: 0.2538326488326488\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_embedding for query q4 is: 0.6359969659969661\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_embedding for query q5 is: 0.267980352980353\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_embedding for query q6 is: 0.3687418137418138\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_ref_embedding for query q1 is: 0.0\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_ref_embedding for query q2 is: 0.16375494875494878\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_ref_embedding for query q3 is: 0.22121526621526624\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_ref_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_ref_embedding for query q5 is: 0.12100029600029599\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with tab_cap_ref_embedding for query q6 is: 0.15652532652532652\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with weighted_embedding for query q1 is: 0.0\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with weighted_embedding for query q2 is: 0.09899304399304398\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with weighted_embedding for query q3 is: 0.2704464054464054\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with weighted_embedding for query q4 is: 0.6603315203315204\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with weighted_embedding for query q5 is: 0.1467650867650868\n",
      "Avg Precision@15 of sentence-transformers/sentence-t5-large with weighted_embedding for query q6 is: 0.27949235949235957\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_embedding for query q1 is: 0.02595071595071595\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_embedding for query q2 is: 0.019890109890109888\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_embedding for query q3 is: 0.1513194213194213\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_embedding for query q5 is: 0.09142117142117141\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_embedding for query q6 is: 0.06597550597550597\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_embedding for query q1 is: 0.10221648721648723\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_embedding for query q2 is: 0.0044444444444444444\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_embedding for query q3 is: 0.3480902430902431\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_embedding for query q4 is: 0.5959721759721762\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_embedding for query q5 is: 0.11264383764383763\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_embedding for query q6 is: 0.1402083102083102\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_ref_embedding for query q1 is: 0.057881932881932885\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_ref_embedding for query q2 is: 0.0\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_ref_embedding for query q3 is: 0.049491619491619496\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_ref_embedding for query q4 is: 0.6827429977429978\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_ref_embedding for query q5 is: 0.10199911199911199\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with tab_cap_ref_embedding for query q6 is: 0.09697672697672698\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with weighted_embedding for query q1 is: 0.04182373182373182\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with weighted_embedding for query q2 is: 0.04002479002479002\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with weighted_embedding for query q3 is: 0.3480902430902431\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with weighted_embedding for query q4 is: 0.6538541088541089\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with weighted_embedding for query q5 is: 0.08097550597550597\n",
      "Avg Precision@15 of sentence-transformers/all-MiniLM-L6-v2 with weighted_embedding for query q6 is: 0.08332759832759833\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_embedding for query q1 is: 0.15454859954859962\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_embedding for query q2 is: 0.0\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_embedding for query q3 is: 0.27576386576386575\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_embedding for query q5 is: 0.06708828208828209\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_embedding for query q6 is: 0.07708661708661708\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_embedding for query q1 is: 0.25354164354164355\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_embedding for query q2 is: 0.009206349206349208\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_embedding for query q3 is: 0.4336457986457986\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_embedding for query q4 is: 0.5959721759721762\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_embedding for query q6 is: 0.009206349206349208\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_ref_embedding for query q1 is: 0.27576386576386575\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_ref_embedding for query q2 is: 0.0\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_ref_embedding for query q3 is: 0.14501905501905504\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_ref_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_ref_embedding for query q5 is: 0.024334554334554333\n",
      "Avg Precision@15 of deepset/sentence_bert with tab_cap_ref_embedding for query q6 is: 0.10711307211307212\n",
      "Avg Precision@15 of deepset/sentence_bert with weighted_embedding for query q1 is: 0.21243053243053242\n",
      "Avg Precision@15 of deepset/sentence_bert with weighted_embedding for query q2 is: 0.019890109890109888\n",
      "Avg Precision@15 of deepset/sentence_bert with weighted_embedding for query q3 is: 0.14996854996855\n",
      "Avg Precision@15 of deepset/sentence_bert with weighted_embedding for query q4 is: 0.6782985532985534\n",
      "Avg Precision@15 of deepset/sentence_bert with weighted_embedding for query q5 is: 0.0\n",
      "Avg Precision@15 of deepset/sentence_bert with weighted_embedding for query q6 is: 0.08097550597550597\n"
     ]
    }
   ],
   "source": [
    "# Precision at k\n",
    "def precision_at_k(k: int):\n",
    "    precision_values: dict[str, dict[str, dict[str, float]]] = {}\n",
    "\n",
    "    for model, methods in results.items():\n",
    "        precision_values[model] = {}\n",
    "        for method, queries in methods.items():\n",
    "            precision_values[model][method] = {}\n",
    "            for query_id, ranking in queries.items():\n",
    "                relevant = 0\n",
    "                for pos, table_id in ranking.items():\n",
    "                    if int(pos) > k: break\n",
    "                    \n",
    "                    rel: float = 0\n",
    "                    \n",
    "                    # find relevance\n",
    "                    for _, gt_table in ground_truth[query_id].items():\n",
    "                        gt_table_id = gt_table[\"paper_id\"] + \"#\" + gt_table[\"table_id\"]\n",
    "                        if table_id == gt_table_id:\n",
    "                            rel = float(gt_table[\"rel\"])\n",
    "                    \n",
    "                    if rel > 0: relevant += 1\n",
    "                \n",
    "                precision = relevant / k\n",
    "                precision_values[model][method][query_id] = precision\n",
    "    \n",
    "    return precision_values\n",
    "\n",
    "# Avg Precision at K\n",
    "K = 15\n",
    "# model -> method -> query, avg_precision@k\n",
    "ap_values: dict[str, dict[str, dict[str, float]]] = {}\n",
    "\n",
    "for model, methods in results.items():\n",
    "    ap_values[model] = {}\n",
    "    for method, queries in methods.items():\n",
    "        ap_values[model][method] = {}\n",
    "        \n",
    "        for query_id, ranking in queries.items():\n",
    "            sum_p = 0\n",
    "            \n",
    "            for k in range(1, K + 1):\n",
    "                precision_values_at_k = precision_at_k(k)\n",
    "                sum_p += precision_values_at_k[model][method][query_id]\n",
    "                \n",
    "            ap_values[model][method][query_id] = sum_p / K\n",
    "            print(f\"Avg Precision@{K} of {model} with {method} for query {query_id} is: {ap_values[model][method][query_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@15 for lucene using method: bm25 is 0.23478216228216234.\n",
      "MAP@15 for bert-base-uncased using method: tab_embedding is 0.19814950481617152.\n",
      "MAP@15 for bert-base-uncased using method: tab_cap_embedding is 0.22713511796845132.\n",
      "MAP@15 for bert-base-uncased using method: tab_cap_ref_embedding is 0.2363376130042797.\n",
      "MAP@15 for bert-base-uncased using method: weighted_embedding is 0.17162753912753914.\n",
      "MAP@15 for distilbert-base-uncased using method: tab_embedding is 0.18884643134643134.\n",
      "MAP@15 for distilbert-base-uncased using method: tab_cap_embedding is 0.19804260554260553.\n",
      "MAP@15 for distilbert-base-uncased using method: tab_cap_ref_embedding is 0.1942961667961668.\n",
      "MAP@15 for distilbert-base-uncased using method: weighted_embedding is 0.11752768836102168.\n",
      "MAP@15 for allenai/scibert_scivocab_uncased using method: tab_embedding is 0.13292038208704873.\n",
      "MAP@15 for allenai/scibert_scivocab_uncased using method: tab_cap_embedding is 0.07254615754615755.\n",
      "MAP@15 for allenai/scibert_scivocab_uncased using method: tab_cap_ref_embedding is 0.07621967538634206.\n",
      "MAP@15 for allenai/scibert_scivocab_uncased using method: weighted_embedding is 0.1322990897990898.\n",
      "MAP@15 for all-mpnet-base-v2 using method: tab_embedding is 0.17163207163207164.\n",
      "MAP@15 for all-mpnet-base-v2 using method: tab_cap_embedding is 0.20054383887717228.\n",
      "MAP@15 for all-mpnet-base-v2 using method: tab_cap_ref_embedding is 0.26419269002602336.\n",
      "MAP@15 for all-mpnet-base-v2 using method: weighted_embedding is 0.18134670884670887.\n",
      "MAP@15 for sentence-transformers/sentence-t5-large using method: tab_embedding is 0.18335097001763667.\n",
      "MAP@15 for sentence-transformers/sentence-t5-large using method: tab_cap_embedding is 0.2544252969252969.\n",
      "MAP@15 for sentence-transformers/sentence-t5-large using method: tab_cap_ref_embedding is 0.22346573179906518.\n",
      "MAP@15 for sentence-transformers/sentence-t5-large using method: weighted_embedding is 0.24267140267140266.\n",
      "MAP@15 for sentence-transformers/all-MiniLM-L6-v2 using method: tab_embedding is 0.17214257964257965.\n",
      "MAP@15 for sentence-transformers/all-MiniLM-L6-v2 using method: tab_cap_embedding is 0.21726258309591648.\n",
      "MAP@15 for sentence-transformers/all-MiniLM-L6-v2 using method: tab_cap_ref_embedding is 0.16484873151539822.\n",
      "MAP@15 for sentence-transformers/all-MiniLM-L6-v2 using method: weighted_embedding is 0.20801599634932968.\n",
      "MAP@15 for deepset/sentence_bert using method: tab_embedding is 0.20879765296431965.\n",
      "MAP@15 for deepset/sentence_bert using method: tab_cap_embedding is 0.21692871942871947.\n",
      "MAP@15 for deepset/sentence_bert using method: tab_cap_ref_embedding is 0.20508818342151677.\n",
      "MAP@15 for deepset/sentence_bert using method: weighted_embedding is 0.19026054192720862.\n"
     ]
    }
   ],
   "source": [
    "# MAP@K (K è quello sopra)\n",
    "map_values: dict[str, dict[str, float]] = {}\n",
    "\n",
    "for model, methods in results.items():\n",
    "    map_values[model] = {}\n",
    "    for method, queries in methods.items():\n",
    "        sum_ap = 0\n",
    "        \n",
    "        for avg_prec in ap_values[model][method].values():\n",
    "            sum_ap += avg_prec\n",
    "        \n",
    "        map_value = sum_ap / num_queries\n",
    "        map_values[model][method] = map_value\n",
    "            \n",
    "        print(f\"MAP@{K} for {model} using method: {method} is {map_value}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
