{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We use gt for evaluations. We do blocking and pw on gt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' module_dir = \"../pairwise_matching\"\\nmodule_path = \"../pairwise_matching/rll_pairwise_matching.py\"\\n\\n# Add the directory to sys.path (to allow imports inside the module to work)\\nif module_dir not in sys.path:\\n    sys.path.append(module_dir)\\n\\n# Load the module dynamically\\nmodule_name = \"your_module_name\"\\nspec = importlib.util.spec_from_file_location(module_name, module_path)\\njw_matcher = importlib.util.module_from_spec(spec)\\nspec.loader.exec_module(jw_matcher) '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "module_dir = \"../pairwise_matching/ditto\"\n",
    "module_path = \"../pairwise_matching/ditto/matcher.py\"\n",
    "\n",
    "# Add the directory to sys.path (to allow imports inside the module to work)\n",
    "if module_dir not in sys.path:\n",
    "    sys.path.append(module_dir)\n",
    "\n",
    "# Load the module dynamically\n",
    "module_name = \"your_module_name\"\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "ditto_matcher = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(ditto_matcher)\n",
    "\n",
    "module_dir = \"../pairwise_matching\"\n",
    "module_path = \"../pairwise_matching/rll_pairwise_matching.py\"\n",
    "\n",
    "# Add the directory to sys.path (to allow imports inside the module to work)\n",
    "if module_dir not in sys.path:\n",
    "    sys.path.append(module_dir)\n",
    "\n",
    "# Load the module dynamically\n",
    "module_name = \"your_module_name\"\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "jw_matcher = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(jw_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609295\n",
      "USING CUDAAA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "106it [00:00, 212015.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_f1 = 0.9465648854961832\n",
      "real_f1 = 0.9465648854961832\n",
      "106805\n",
      "USING CUDAAA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "106it [00:00, 211813.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_f1 = 0.9465648854961832\n",
      "real_f1 = 0.9465648854961832\n"
     ]
    }
   ],
   "source": [
    "blocking_paths = [\"lsh_bigram_gt_blocking.json\", \"lsh_words_gt_blocking.json\", \"lsh_bigram_aq_gt_blocking.json\", \"lsh_words_aq_gt_blocking.json\" ]\n",
    "pairwise_methods = [\"jarowinkler\", \"ditto\", \"deepmatcher\"]\n",
    "\n",
    "for blocking_path in blocking_paths:\n",
    "        pairs: list = pm_evaluation.get_pairs_for_pairwise_matching(blocking_path)\n",
    "        print(len(pairs))\n",
    "        \n",
    "        for pw_method in pairwise_methods:\n",
    "            if pw_method == \"jarowinkler\":\n",
    "                for threshold in [0.7, 0.75]:\n",
    "                    # do jarowinkler pw and save to file\n",
    "                    jw_matcher.pairwise_matching(blocking_path, threshold)\n",
    "            if pw_method == \"ditto\":\n",
    "                blocking_path = blocking_path.replace(\"json\", \"txt\")\n",
    "                ditto_matcher.pairwise_matching(pairs_to_evaluate=pairs,\n",
    "                                                checkpoint_path='../pairwise_matching/ditto/checkpoints/',\n",
    "                                                ditto_path='../pairwise_matching/ditto/',\n",
    "                                                output_path='results/ditto/' + blocking_path,\n",
    "                                                use_gpu=True, gt_eval=True)\n",
    "            elif pw_method == \"deepmatcher\":\n",
    "                # do dm pw aoooo\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval of pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDEEPMATCHER\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[0;32m     10\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, filename)\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mpm_evaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../ground_truth/gt.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Coding\\IDD\\de-projects\\project-5\\src\\evaluation\\pm_evaluation.py:25\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(gt_file_path, predict_file_path)\u001b[0m\n\u001b[0;32m     22\u001b[0m     predicted_pairs \u001b[38;5;241m=\u001b[39m predict_file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# To take only the predicted pairs of the same vocabulary as the GT \u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m gt_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_gt_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_lines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# True positive, False positive and False negative sets\u001b[39;00m\n\u001b[0;32m     28\u001b[0m tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mf:\\Coding\\IDD\\de-projects\\project-5\\src\\evaluation\\pm_evaluation.py:85\u001b[0m, in \u001b[0;36mextract_gt_pairs\u001b[1;34m(gt_lines)\u001b[0m\n\u001b[0;32m     81\u001b[0m     pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m || \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     83\u001b[0m     gt_pairs\u001b[38;5;241m.\u001b[39madd(pair)\n\u001b[1;32m---> 85\u001b[0m gt_pairs \u001b[38;5;241m=\u001b[39m {normalize_pair(pair) \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m gt_pairs}\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gt_pairs\n",
      "File \u001b[1;32mf:\\Coding\\IDD\\de-projects\\project-5\\src\\evaluation\\pm_evaluation.py:85\u001b[0m, in \u001b[0;36m<setcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m     pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m || \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     83\u001b[0m     gt_pairs\u001b[38;5;241m.\u001b[39madd(pair)\n\u001b[1;32m---> 85\u001b[0m gt_pairs \u001b[38;5;241m=\u001b[39m {normalize_pair(pair) \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m gt_pairs}\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gt_pairs\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "RED = \"\\033[31m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "for dirpath, _, filenames in os.walk(\"results\"):\n",
    "    if dirpath != \"results\":\n",
    "        name = dirpath.split(\"\\\\\")[1].upper()\n",
    "        print(f\"{RED}{name}{RESET}\")\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(dirpath, filename)\n",
    "        pm_evaluation.evaluate(\"../ground_truth/gt.txt\", filepath)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution Times\n",
    "\n",
    "##### Ditto\n",
    "Time for ditto pairwise matching on 65.895 items - 609295 pairs after lsh_bigram_blocking: **71 minutes.**\n",
    "\n",
    "Time for ditto pairwise matching on gt items with both blocking methods: **Average of 1.6 seconds**\n",
    "\n",
    "##### Jarowinkler\n",
    "Time for jarowinkler pairwise matching on 65.895 items after blocking: **Average of  25 seconds**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_venv)",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
