{
    "Dataset": [
        "Dataset: Virtual KITTIâ†’KITTI",
        "Dataset: Cityscapes",
        "Dataset: CUB",
        "Dataset: HMDB-51",
        "Dataset: HMDB-38",
        "Dataset: 11.6K synthetic test instances",
        "dataset: CUB",
        "Dataset: NAB",
        "Dataset: Syn-only",
        "Dataset: CP-only",
        "Dataset: Real-only",
        "Dataset: ID",
        "Dataset: Form OOD",
        "Metric: OOD-N",
        "Metric: OOD-F",
        "Metric: OOD-1000",
        "Training Data: Original",
        "Training Data: Original + Generated",
        "Training Data: Original + Mixed",
        "Dataset: UCF-101",
        "Dataset: UCF-25",
        "Dataset: DCASE 2018",
        "Dataset: DCASE 2019",
        "Approach: DPSDA-FL",
        "Setting: Real only",
        "Setting: Videos+Real",
        "Setting: Real-only"
    ],
    "Method": [
        "Method: Non Adapt",
        "Method: Input Level Adapt",
        "Method: Output Level Adapt",
        "Method: Input&Ouput Adapt",
        "Method: Ours (Non Adapt)",
        "Method: Ours (Input-level Adapt)",
        "Method: Ours (Output-level Adapt)",
        "Method: Ours (Input&Output Adapt)",
        "Method: image transform network guided by task network",
        "Method: image transform network guided by task network with additional depth input",
        "Method: image transform network guided by task network with additional semantic label input",
        "Method: image transform network guided by task network with both depth and semantic labels as additional input",
        "classifier: Nearest Neighbor",
        "Method: Nearest Neighbor",
        "Method: Nearest neighbor",
        "classifier: Logistic Regression",
        "Method: Logistic Regression",
        "Method: Logistic regression",
        "classifier: Softmax Regression",
        "Method: Softmax Regression",
        "Method: Softmax regression",
        "Approach: Chain-of-Thought",
        "Approach: FedAvg",
        "Approach: FedProx",
        "Method: non-adaptive baseline",
        "Method: image translation with CycleGAN",
        "Method: FCNs Wld",
        "Method: Curriculum",
        "Method: Cross-City",
        "Method: ROAD-Net",
        "Method: Tsai etal.",
        "Method: Sankaranarayanan etal.",
        "Method: CBST",
        "Method: ProtoNet",
        "Method: MetaIRNet (Ours)",
        "Method: MAML",
        "Method: Network-1",
        "Method: iDT+FV",
        "Method: L 2 STM",
        "Method: CoViar",
        "Method: OFF",
        "Method: Two-stream I3D",
        "Method: Network-2 (all of the generated videos)",
        "Method: K-means",
        "Method: DBSCAN",
        "Method: Gen-Hybrid",
        "Method: TSN-2M",
        "Method: TSN-3M",
        "Method: Cool-TSN",
        "Approach: 2-Shot Prompting",
        "Approach: 8-Shot Prompting",
        "Method: Two-stream",
        "Method: Two-stream LSTM",
        "Method: Two-stream MiCT",
        "Method: Network-2",
        "Method: Network-2 (half of the generated videos)"
    ],
    "Class": [
        "Category: road",
        "Class: road",
        "Category: building",
        "Category: pole",
        "Category: traffic light",
        "Category: traffic sign",
        "Class: traffic light",
        "Class: traffic sign",
        "Category: vegetation",
        "Category: terrain",
        "Class: vegetation",
        "Category: sky",
        "Class: sky",
        "Category: car",
        "Category: truck",
        "Class: car",
        "Class: Truck",
        "Class: building",
        "Class: wall",
        "Class: fence",
        "Class: pole",
        "Class: rider",
        "Class: motorbike",
        "Class: bicycle",
        "Class: sidewalk",
        "Class: person",
        "Class: bus",
        "Class: Plane",
        "Class: Cat",
        "Class: Ship"
    ],
    "Base Network": [
        "Backbone: Conv4",
        "Base Network: ResNet18",
        "Base Network: Conv-4",
        "Model: ResNet18",
        "Backbone: VGG"
    ],
    "Number of Synthetic Videos": [
        "Number of synthetic videos: 4000",
        "Number of synthetic videos: 8000",
        "Number of Synthetic Videos: 0",
        "Number of Synthetic Videos: 2500",
        "Number of Synthetic Videos: 5000"
    ],
    "Model": [
        "Model: baseline",
        "Model: GPT4",
        "Model: gpt-4-turbo-2024-04-09",
        "Model: gpt-4o-2024-05-13",
        "Model: gpt-4-turbo-0125-preview",
        "Model: gpt-4-turbo-1106-preview",
        "Model: gpt-4",
        "Model: Gemini Pro 1.5 (May 2024)",
        "Model: MAML",
        "Model: SEDB",
        "Model: SEDB & IFD",
        "Method: 3D-ResNet-101",
        "Model: ResNet100",
        "Model: ResNet50",
        "Model: ProtoNet",
        "Model: IFD",
        "Model: MobileFaceNet",
        "Model: Phi-3-Mini-4K-Instruct",
        "Model: Claude 3.5 Sonnet",
        "Model: Claude 3 Opus",
        "Model: Gemini Ultra",
        "Model: MetaIRNet",
        "Model: MatchingNet",
        "Model: RelationNet",
        "Method: MatchingNet",
        "Method: RelationNet",
        "Model: Llama-2-7B",
        "Model: Llama-3-8B-Instruct",
        "Model: Llama-3-70B-Instruct",
        "Model: Deepseek-Coder-33B",
        "Model: DeepSeek LLM 67B Chat",
        "Model: DeepSeek-Coder-V2-Instruct",
        "Model: Yi-1.5-34B-Chat",
        "Model: Qwen1.5-72B-Chat",
        "Model: Qwen1.5-110B-Chat",
        "Model: Qwen2-7B-Instruct",
        "Model: Qwen2-72B-Instruct",
        "Model: Qwen2-7B (fine-tuned w/ the 1.07M synthesized instances)"
    ],
    "Number of images": [
        "Image Count: 1755",
        "Image Count: 4387",
        "Image Count: 8775",
        "Image Count: 17550",
        "Image Count: 35100",
        "Image Count: 70200",
        "Number of images: 50",
        "Number of images: 100",
        "Number of images: 150",
        "Number of images: 200",
        "Number of images: 300",
        "Number of images: 400",
        "Number of images: 500",
        "Number of images: 600"
    ],
    "Fruit": [
        "Fruit: Apple",
        "Fruit: Banana",
        "Fruit: Strawberry",
        "Fruit: Orange",
        "Fruit: Peach",
        "Fruit: Plum",
        "Item: Apple",
        "Item: Banana",
        "Item: Strawberry",
        "Item: Orange",
        "Item: Peach",
        "Item: Plum",
        "Item: Total"
    ],
    "Model Size": [
        "Parameter Size: 65.2M",
        "Parameter Size: 43.6M",
        "Parameter Size: 24.0M",
        "Parameter Size: 1.1M",
        "Model Size: 67B",
        "Model Size: 3.8B",
        "Model Size: 34B",
        "Model Size: 72B",
        "Model Size: 110B",
        "Model Size: 7B",
        "Model Size: 8B",
        "Model Size: 70B",
        "Model Size: ?",
        "Model Size: 236B/21B"
    ]
}